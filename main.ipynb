{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DataSet\n",
    "train_data = pd.read_csv('D:\\FPTUni\\SP24\\ADY201m\\Project\\DataSet\\Bioassay_Datasets\\AID456red_train.csv')\n",
    "test_data = pd.read_csv('D:\\FPTUni\\SP24\\ADY201m\\Project\\DataSet\\Bioassay_Datasets\\AID456red_test.csv')\n",
    "\n",
    "# Ghi tên file vào sau khi check - Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEG_01_NEG</th>\n",
       "      <th>NEG_02_NEG</th>\n",
       "      <th>NEG_03_NEG</th>\n",
       "      <th>NEG_04_NEG</th>\n",
       "      <th>NEG_05_NEG</th>\n",
       "      <th>NEG_06_NEG</th>\n",
       "      <th>NEG_07_NEG</th>\n",
       "      <th>NEG_03_POS</th>\n",
       "      <th>NEG_04_POS</th>\n",
       "      <th>NEG_05_POS</th>\n",
       "      <th>...</th>\n",
       "      <th>WBN_LP_H_1.00</th>\n",
       "      <th>XLogP</th>\n",
       "      <th>PSA</th>\n",
       "      <th>NumRot</th>\n",
       "      <th>NumHBA</th>\n",
       "      <th>NumHBD</th>\n",
       "      <th>MW</th>\n",
       "      <th>BBB</th>\n",
       "      <th>BadGroup</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.3789</td>\n",
       "      <td>0.790</td>\n",
       "      <td>156.91</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>464.511</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2918</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>173.45</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>461.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1641</td>\n",
       "      <td>0.197</td>\n",
       "      <td>138.20</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>462.539</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.3241</td>\n",
       "      <td>0.702</td>\n",
       "      <td>138.20</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>460.523</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.3003</td>\n",
       "      <td>1.649</td>\n",
       "      <td>86.71</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>334.416</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Inactive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NEG_01_NEG  NEG_02_NEG  NEG_03_NEG  NEG_04_NEG  NEG_05_NEG  NEG_06_NEG  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   NEG_07_NEG  NEG_03_POS  NEG_04_POS  NEG_05_POS  ...  WBN_LP_H_1.00  XLogP  \\\n",
       "0           0           0           0           0  ...         3.3789  0.790   \n",
       "1           0           0           0           0  ...         3.2918 -0.749   \n",
       "2           0           0           0           0  ...         3.1641  0.197   \n",
       "3           0           0           0           0  ...         3.3241  0.702   \n",
       "4           0           0           0           0  ...         3.3003  1.649   \n",
       "\n",
       "      PSA  NumRot  NumHBA  NumHBD       MW  BBB  BadGroup   Outcome  \n",
       "0  156.91       3       9       6  464.511    0         0  Inactive  \n",
       "1  173.45       8      11       4  461.500    0         0  Inactive  \n",
       "2  138.20       7       8       3  462.539    0         2  Inactive  \n",
       "3  138.20       7       8       3  460.523    0         3  Inactive  \n",
       "4   86.71      12       6       2  334.416    0         0  Inactive  \n",
       "\n",
       "[5 rows x 154 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 5 rows of the train data\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7986 entries, 0 to 7985\n",
      "Columns: 154 entries, NEG_01_NEG to Outcome\n",
      "dtypes: float64(27), int64(126), object(1)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check info of the train data\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEG_01_NEG</th>\n",
       "      <th>NEG_02_NEG</th>\n",
       "      <th>NEG_03_NEG</th>\n",
       "      <th>NEG_04_NEG</th>\n",
       "      <th>NEG_05_NEG</th>\n",
       "      <th>NEG_06_NEG</th>\n",
       "      <th>NEG_07_NEG</th>\n",
       "      <th>NEG_03_POS</th>\n",
       "      <th>NEG_04_POS</th>\n",
       "      <th>NEG_05_POS</th>\n",
       "      <th>...</th>\n",
       "      <th>WBN_LP_L_1.00</th>\n",
       "      <th>WBN_LP_H_1.00</th>\n",
       "      <th>XLogP</th>\n",
       "      <th>PSA</th>\n",
       "      <th>NumRot</th>\n",
       "      <th>NumHBA</th>\n",
       "      <th>NumHBD</th>\n",
       "      <th>MW</th>\n",
       "      <th>BBB</th>\n",
       "      <th>BadGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "      <td>7986.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.273197</td>\n",
       "      <td>3.679769</td>\n",
       "      <td>2.641313</td>\n",
       "      <td>83.887087</td>\n",
       "      <td>5.561232</td>\n",
       "      <td>4.256324</td>\n",
       "      <td>0.902705</td>\n",
       "      <td>346.995594</td>\n",
       "      <td>0.292136</td>\n",
       "      <td>0.201102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.025016</td>\n",
       "      <td>0.052417</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>0.053592</td>\n",
       "      <td>0.029595</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>0.019379</td>\n",
       "      <td>0.029595</td>\n",
       "      <td>0.029595</td>\n",
       "      <td>0.022376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269668</td>\n",
       "      <td>0.240876</td>\n",
       "      <td>1.345485</td>\n",
       "      <td>30.016955</td>\n",
       "      <td>2.541147</td>\n",
       "      <td>1.957862</td>\n",
       "      <td>0.815120</td>\n",
       "      <td>75.308950</td>\n",
       "      <td>0.454773</td>\n",
       "      <td>0.461007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.802900</td>\n",
       "      <td>2.071300</td>\n",
       "      <td>-3.282000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.151000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.550850</td>\n",
       "      <td>3.532100</td>\n",
       "      <td>1.772000</td>\n",
       "      <td>63.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>294.311000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.210300</td>\n",
       "      <td>3.665600</td>\n",
       "      <td>2.641500</td>\n",
       "      <td>82.165000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>345.394000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.047600</td>\n",
       "      <td>3.853200</td>\n",
       "      <td>3.536750</td>\n",
       "      <td>102.327500</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>400.522250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.064900</td>\n",
       "      <td>4.452900</td>\n",
       "      <td>8.292000</td>\n",
       "      <td>255.980000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>914.186000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NEG_01_NEG   NEG_02_NEG   NEG_03_NEG   NEG_04_NEG   NEG_05_NEG  \\\n",
       "count  7986.000000  7986.000000  7986.000000  7986.000000  7986.000000   \n",
       "mean      0.000626     0.002755     0.000125     0.002880     0.000877   \n",
       "std       0.025016     0.052417     0.011190     0.053592     0.029595   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        NEG_06_NEG   NEG_07_NEG   NEG_03_POS   NEG_04_POS   NEG_05_POS  ...  \\\n",
       "count  7986.000000  7986.000000  7986.000000  7986.000000  7986.000000  ...   \n",
       "mean      0.000125     0.000376     0.000877     0.000877     0.000501  ...   \n",
       "std       0.011190     0.019379     0.029595     0.029595     0.022376  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "       WBN_LP_L_1.00  WBN_LP_H_1.00        XLogP          PSA       NumRot  \\\n",
       "count    7986.000000    7986.000000  7986.000000  7986.000000  7986.000000   \n",
       "mean       -3.273197       3.679769     2.641313    83.887087     5.561232   \n",
       "std         0.269668       0.240876     1.345485    30.016955     2.541147   \n",
       "min        -3.802900       2.071300    -3.282000     0.000000     0.000000   \n",
       "25%        -3.550850       3.532100     1.772000    63.250000     4.000000   \n",
       "50%        -3.210300       3.665600     2.641500    82.165000     5.000000   \n",
       "75%        -3.047600       3.853200     3.536750   102.327500     7.000000   \n",
       "max        -2.064900       4.452900     8.292000   255.980000    15.000000   \n",
       "\n",
       "            NumHBA       NumHBD           MW          BBB     BadGroup  \n",
       "count  7986.000000  7986.000000  7986.000000  7986.000000  7986.000000  \n",
       "mean      4.256324     0.902705   346.995594     0.292136     0.201102  \n",
       "std       1.957862     0.815120    75.308950     0.454773     0.461007  \n",
       "min       0.000000     0.000000   125.151000     0.000000     0.000000  \n",
       "25%       3.000000     0.000000   294.311000     0.000000     0.000000  \n",
       "50%       4.000000     1.000000   345.394000     0.000000     0.000000  \n",
       "75%       6.000000     1.000000   400.522250     1.000000     0.000000  \n",
       "max      17.000000     7.000000   914.186000     1.000000     4.000000  \n",
       "\n",
       "[8 rows x 153 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the train data\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NEG_01_NEG', 'NEG_02_NEG', 'NEG_03_NEG', 'NEG_04_NEG', 'NEG_05_NEG',\n",
       "       'NEG_06_NEG', 'NEG_07_NEG', 'NEG_03_POS', 'NEG_04_POS', 'NEG_05_POS',\n",
       "       ...\n",
       "       'WBN_LP_H_1.00', 'XLogP', 'PSA', 'NumRot', 'NumHBA', 'NumHBD', 'MW',\n",
       "       'BBB', 'BadGroup', 'Outcome'],\n",
       "      dtype='object', length=154)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all columns name of the train data\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "Inactive    7964\n",
       "Active        22\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count data type of Outcome column\n",
    "train_data['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Như bạn đã thấy, cách biệt giữa số lượng giữa 2 nhóm là rất lớn, điều này có thể dẫn đến hiện tượng mô hình dự đoán không tốt.\n",
    "# Để giải quyết vấn đề này, chúng ta sẽ bắt đầu nghiên cứu các phương pháp để giải quyết.\n",
    "# Được rồi, có vẻ nghiên cứu xong nó giải quyết ngu hơn =))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Data manipulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=5000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=5000)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trước tiên thì chúng ta sẽ thử train model với dữ liệu gốc này để xem kết quả như thế nào\n",
    "\n",
    "\n",
    "# Split the train data into X_train1 and y_train1\n",
    "X_train1 = train_data.drop('Outcome', axis=1)\n",
    "y_train1 = train_data['Outcome']\n",
    "\n",
    "# Train the model\n",
    "model1 = LogisticRegression()\n",
    "### Change the max_iter to 5000 to avoid the warning\n",
    "model1.max_iter = 5000\n",
    "model1.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1229]\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra và thiết lập max_iter cho Logistic Regression\n",
    "print(model1.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974949899799599"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the test data into X_test and y_test\n",
    "X_test1 = test_data.drop('Outcome', axis=1)\n",
    "y_test1 = test_data['Outcome']\n",
    "\n",
    "# Predict the test data\n",
    "y_test_pred1 = model1.predict(X_test1)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_score(y_test1, y_test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47831, 155) (100, 155)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "Active      50\n",
       "Inactive    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sau đó chúng ta sẽ thử cấu hình với dữ liệu bằng UnderSampling\n",
    "\n",
    "# Define the undersampling method\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "# Fit and apply the transform\n",
    "X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\n",
    "\n",
    "# Count the number of 0 and 1 in the source\n",
    "y_train.value_counts()\n",
    "\n",
    "# Count the number of 0 and 1 in the target\n",
    "y_train_under.value_counts()\n",
    "\n",
    "# Print the shape of the source and the target\n",
    "print(X_train.shape, X_train_under.shape)\n",
    "\n",
    "# Count data type of Outcome column\n",
    "y_train_under.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7273563602910429"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model dựa trên dữ liệu đã undersampling\n",
    "model2 = LogisticRegression()\n",
    "model2.max_iter = 5000\n",
    "model2.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Predict the test data\n",
    "y_test_pred2 = model2.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_score(y_test, y_test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47831, 155) (95562, 155)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "Active      47781\n",
       "Inactive    47781\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cấu hình dữ liệu bằng OverSampling\n",
    "\n",
    "# Define the oversampling method\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "# Fit and apply the transform\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "# Count the number of 0 and 1 in the source\n",
    "y_train.value_counts()\n",
    "\n",
    "# Count the number of 0 and 1 in the target\n",
    "y_train_over.value_counts()\n",
    "\n",
    "# Print the shape of the source and the target\n",
    "print(X_train.shape, X_train_over.shape)\n",
    "\n",
    "# Count data type of Outcome column\n",
    "y_train_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8709542527389813"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model dựa trên dữ liệu đã oversampling\n",
    "model3 = LogisticRegression()\n",
    "model3.max_iter = 5000\n",
    "model3.fit(X_train_over, y_train_over)\n",
    "\n",
    "# Predict the test data\n",
    "y_test_pred3 = model3.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_score(y_test, y_test_pred3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47831, 155) (100, 155)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "Active      50\n",
       "Inactive    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chúng ta kết hợp cả 2 phương pháp UnderSampling và OverSampling\n",
    "\n",
    "# Define the undersampling method\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "# Fit and apply the transform\n",
    "X_train_combined, y_train_combined = undersample.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the oversampling method\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "# Fit and apply the transform\n",
    "X_train_combined, y_train_combined = oversample.fit_resample(X_train_combined, y_train_combined)\n",
    "\n",
    "# Count the number of 0 and 1 in the source\n",
    "y_train.value_counts()\n",
    "\n",
    "# Count the number of 0 and 1 in the target\n",
    "y_train_combined.value_counts()\n",
    "\n",
    "# Print the shape of the source and the target\n",
    "print(X_train.shape, X_train_combined.shape)\n",
    "\n",
    "# Count data type of Outcome column\n",
    "y_train_combined.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7158150037634858"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model dựa trên dữ liệu đã undersampling và oversampling\n",
    "model4 = LogisticRegression()\n",
    "model4.max_iter = 5000\n",
    "model4.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Predict the test data\n",
    "y_test_pred4 = model4.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_score(y_test, y_test_pred4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Handling loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001045347159791767 0.9989546528402082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9989964037802125"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sử dụng Cross_Entropy Weightied để cân bằng dữ liệu\n",
    "\n",
    "# Split the train data into X_train and y_train\n",
    "x_train5 = train_data.drop('Outcome', axis=1)\n",
    "x_test5 = test_data.drop('Outcome', axis=1)\n",
    "\n",
    "# Chuyển đổi nhãn sang số\n",
    "y_train_num = y_train.replace({'Active': 0, 'Inactive': 1})\n",
    "y_test_num = y_test.replace({'Active': 0, 'Inactive': 1})\n",
    "\n",
    "# Tính toán tổng số mẫu và số mẫu của mỗi lớp\n",
    "total_samples = len(y_train_num)\n",
    "num_samples_class0 = np.sum(y_train_num == 0)\n",
    "num_samples_class1 = np.sum(y_train_num == 1)\n",
    "\n",
    "# Tính toán trọng số cho mỗi lớp\n",
    "pos_weight = num_samples_class0 / total_samples\n",
    "neg_weight = num_samples_class1 / total_samples\n",
    "\n",
    "# Print the positive and negative weights\n",
    "print(pos_weight, neg_weight)\n",
    "\n",
    "# Train model dựa trên dữ liệu đã cân bằng bằng Cross_Entropy Weightied\n",
    "model5 = LogisticRegression(class_weight={0: pos_weight, 1: neg_weight})\n",
    "model5.max_iter = 5000\n",
    "model5.fit(X_train, y_train_num)\n",
    "\n",
    "# Predict the test data\n",
    "y_test_pred5 = model5.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_score(y_test_num, y_test_pred5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0027548209366391185 0.9972451790633609\n",
      "Focal Loss on test data: 8.77558477527677e-12\n",
      "Accuracy: 0.9974949899799599\n"
     ]
    }
   ],
   "source": [
    "# Sử dụng Focal Loss để cân bằng dữ liệu\n",
    "\n",
    "# Split the train data into X_train and y_train\n",
    "X_train6 = train_data.drop('Outcome', axis=1)\n",
    "y_train6 = train_data['Outcome']\n",
    "X_test6 = test_data.drop('Outcome', axis=1)\n",
    "y_test6 = test_data['Outcome']\n",
    "\n",
    "# Hàm focal loss\n",
    "def focal_loss(y_true, y_pred_prob, gamma=2.0):\n",
    "    \"\"\"\n",
    "    Tính toán Focal Loss.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Nhãn thực tế (0 hoặc 1).\n",
    "        y_pred_prob: Xác suất dự đoán của lớp dương.\n",
    "        gamma: Tham số gamma trong hàm Focal Loss (mặc định là 2).\n",
    "        \n",
    "    Returns:\n",
    "        Giá trị Focal Loss.\n",
    "    \"\"\"\n",
    "    # Tính toán cross entropy loss\n",
    "    ce_loss = - (y_true * np.log(y_pred_prob) + (1 - y_true) * np.log(1 - y_pred_prob))\n",
    "    \n",
    "    # Tính toán focal loss\n",
    "    focal_loss = ce_loss * (1 - y_pred_prob) ** gamma\n",
    "    \n",
    "    return np.mean(focal_loss)\n",
    "\n",
    "# Chuyển đổi nhãn sang số\n",
    "y_train_num6 = y_train6.replace({'Active': 0, 'Inactive': 1})\n",
    "y_test_num6 = y_test6.replace({'Active': 0, 'Inactive': 1})\n",
    "\n",
    "# Tính toán tổng số mẫu và số mẫu của mỗi lớp\n",
    "total_samples6 = len(y_train_num6)\n",
    "num_samples_class06 = np.sum(y_train_num6 == 0)\n",
    "num_samples_class16 = np.sum(y_train_num6 == 1)\n",
    "\n",
    "# Tính toán trọng số cho mỗi lớp\n",
    "pos_weight6 = num_samples_class06 / total_samples6\n",
    "neg_weight6 = num_samples_class16 / total_samples6\n",
    "\n",
    "# Print the positive and negative weights\n",
    "print(pos_weight6, neg_weight6)\n",
    "\n",
    "# Train model dựa trên dữ liệu đã cân bằng bằng Focal Loss\n",
    "model6 = LogisticRegression(class_weight={0: pos_weight6, 1: neg_weight6})\n",
    "model6.max_iter = 5000\n",
    "model6.fit(X_train6, y_train_num6)\n",
    "\n",
    "# Predict the test data\n",
    "y_test_pred_prob6 = model6.predict_proba(X_test6)[:, 1]\n",
    "\n",
    "# Tính toán Focal Loss trên tập kiểm tra\n",
    "focal_loss_value = focal_loss(y_test_num6, y_test_pred_prob6)\n",
    "print(\"Focal Loss on test data:\", focal_loss_value)\n",
    "\n",
    "# Dự đoán nhãn dựa trên ngưỡng 0.5\n",
    "y_test_pred6 = (y_test_pred_prob6 > 0.5).astype(int)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test_num6, y_test_pred6)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47831, 155) (95562, 155)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "Active      47781\n",
       "Inactive    47781\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kỹ thuật SMOTE (Synthetic Minority Over-sampling Technique) để cân bằng dữ liệu\n",
    "\n",
    "# Define the oversampling method\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "\n",
    "# Fit and apply the transform\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Count the number of 0 and 1 in the source\n",
    "y_train.value_counts()\n",
    "\n",
    "# Count the number of 0 and 1 in the target\n",
    "y_train_smote.value_counts()\n",
    "\n",
    "# Print the shape of the source and the target\n",
    "print(X_train.shape, X_train_smote.shape)\n",
    "\n",
    "# Count data type of Outcome column\n",
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.949234757882412"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model dựa trên dữ liệu đã cân bằng bằng SMOTE\n",
    "model7 = LogisticRegression()\n",
    "model7.max_iter = 5000\n",
    "model7.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict the test data\n",
    "y_test_pred7 = model7.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy_score(y_test, y_test_pred7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Ensemble & Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', n_estimators=50)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sử dụng Random Forest trong Ensemble and Boosting để xử lý dữ liệu mất cân bằng\n",
    "\n",
    "# Danh sách các giá trị của các siêu tham số cần tinh chỉnh\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Khởi tạo mô hình Random Forest\n",
    "model8 = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# Tìm kiếm tinh chỉnh siêu tham số bằng Grid Search\n",
    "grid_search = GridSearchCV(estimator=model8, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# In ra các siêu tham số tốt nhất\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Huấn luyện mô hình với các siêu tham số tốt nhất\n",
    "model8s = grid_search.best_estimator_\n",
    "model8s.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990800367985281"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dự đoán nhãn của tập kiểm tra\n",
    "y_test_pred8 = model8s.predict(X_test)\n",
    "\n",
    "# Tính toán độ chính xác của mô hình\n",
    "accuracy_score(y_test, y_test_pred8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Build a Gradient Boosting model to handle imbalanced data\n",
    "\n",
    "# Danh sách các giá trị của các siêu tham số cần tinh chỉnh\n",
    "param_grid = {\n",
    "    'n_estimators': [50],\n",
    "    'learning_rate': [0.01],\n",
    "    'max_depth': [3]\n",
    "}\n",
    "\n",
    "# Create a Gradient Boosting model\n",
    "model9 = GradientBoostingClassifier()\n",
    "\n",
    "# Find the best hyperparameters using Grid Search\n",
    "grid_search = GridSearchCV(estimator=model9, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print all the best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987455047252656"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the best hyperparameters\n",
    "model9s = grid_search.best_estimator_\n",
    "model9s.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test data\n",
    "y_test_pred9 = model9s.predict(X_test)\n",
    "\n",
    "# Cauculate the accuracy of the model\n",
    "accuracy_score(y_test, y_test_pred9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Build a XGBoost model to handle imbalanced data\n",
    "\n",
    "#Split the train data into X_train10 and y_train10\n",
    "X_train10f = train_data.drop('Outcome', axis=1)\n",
    "y_train10f = train_data['Outcome']\n",
    "\n",
    "# Change the label to number\n",
    "X_train10 = X_train10f.replace({'Active': 0, 'Inactive': 1})\n",
    "y_train10 = y_train10f.replace({'Active': 0, 'Inactive': 1})\n",
    "\n",
    "# Split the test data into X_test10 and y_test10\n",
    "X_test10f = test_data.drop('Outcome', axis=1)\n",
    "y_test10f = test_data['Outcome']\n",
    "\n",
    "# Change the label to number\n",
    "X_test10 = X_test10f.replace({'Active': 0, 'Inactive': 1})\n",
    "y_test10 = y_test10f.replace({'Active': 0, 'Inactive': 1})\n",
    "# List of hyperparameters values to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [50],\n",
    "    'learning_rate': [0.01],\n",
    "    'max_depth': [3]\n",
    "}\n",
    "\n",
    "# Create a XGBoost model\n",
    "model10 = XGBClassifier()\n",
    "\n",
    "# Find the best hyperparameters using Grid Search\n",
    "grid_search = GridSearchCV(estimator=model10, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train10, y_train10)\n",
    "\n",
    "# Print all the best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974949899799599"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the best hyperparameters\n",
    "model10s = grid_search.best_estimator_\n",
    "model10s.fit(X_train10, y_train10)\n",
    "\n",
    "# Predict the test data\n",
    "y_test_pred10 = model10s.predict(X_test10)\n",
    "\n",
    "# Cauculate the accuracy of the model\n",
    "accuracy_score(y_test10, y_test_pred10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
